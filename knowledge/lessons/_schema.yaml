# Lesson Schema V2.1
# Defines the structure and lifecycle for lessons in the Composable Development Infrastructure

# 4-Stage Lesson Lifecycle
lifecycle:
  stages:
    proposed:
      description: "Lessons extracted during retrospective phase"
      storage_path: "/knowledge/lessons/proposed/"
      meta_prompt_injection: false
      promotion_trigger: "Human review every 2-3 runs"
      validation_rules:
        - "Must be actionable (contains verb + specific context)"
        - "Must not be vague platitudes"
        - "For failure lessons, root cause must be clear"

    experimental:
      description: "Human-approved lessons being tested in a single run"
      storage_path: "/knowledge/lessons/experimental/"
      meta_prompt_injection: true
      injection_scope: "ONE run only"
      tracking_required:
        - which_run_used_this_lesson
        - baseline_metrics_before_lesson

    validated:
      description: "Lessons that passed experimental testing, awaiting final promotion"
      evaluation_criteria:
        promotion_to_active:
          - "Run succeeded where previous runs failed"
          - "Rubric scores improved in relevant phases"
          - "No new failures correlated with this lesson"
        demotion_to_archived:
          - "Negative correlation with run outcomes"
          - "Conflicting with higher-impact lessons"
          - "No measurable improvement after 3 runs"

    active:
      description: "Validated lessons injected into all future runs"
      storage_path: "/knowledge/lessons/active/"
      meta_prompt_injection: true
      injection_scope: "All runs"
      freshness_cap: 30
      archive_policy: "When cap reached, archive lowest-impact lessons"
      quarterly_review: "Demote lessons that haven't shown impact"

    archived:
      description: "Retired or invalidated lessons"
      storage_path: "/knowledge/lessons/archived/"
      meta_prompt_injection: false
      retention_policy: "Keep for reference and pattern analysis"

# Lesson Schema Definition
lesson_schema:
  required_fields:
    id:
      type: string
      format: "L{run_number}-{seq}"
      example: "L001-003"

    stage:
      type: enum
      values: [proposed, experimental, validated, active, archived]

    created_date:
      type: string
      format: "ISO8601"

    description:
      type: string
      max_length: 200
      requirements: "Must be actionable (contains verb + specific context)"

    type:
      type: enum
      values: [success, failure, observation]

    root_cause:
      type: string
      required_for: [failure]

    evidence:
      type: string

    applicability:
      type: string

  tracking_fields:
    introduced_in_run:
      type: string
      format: "run_id (UUID)"

    tested_in_runs:
      type: array
      items: string

    outcome_correlation:
      type: enum
      values: [positive, negative, neutral]

    impact_score:
      type: number
      min: 0
      max: 100

  lineage_fields:
    meta_prompt_version_compatible:
      type: string

    conflicts_with:
      type: array
      items: string

    supersedes:
      type: string
      nullable: true

# Validation Rules
validation:
  proposal_validation:
    - check: is_actionable
      rule: "Must contain a verb and specific context"
      rejection_if_fail: true

    - check: is_specific
      rule: "Must not be vague platitudes"
      rejection_if_fail: true

    - check: has_root_cause
      rule: "For failure lessons, root cause must be clear"
      rejection_if_fail: true

  expected_rejection_rate: 0.30

  promotion_validation:
    experimental_to_active:
      - check: positive_signal
        criteria:
          - "Run succeeded where previous runs failed"
          - "Rubric scores improved in relevant phases"
          - "No new failures correlated with this lesson"
        outcome_if_positive: promote_to_active
        outcome_if_negative: archive_with_notes
        outcome_if_neutral: "Keep experimental for one more run OR archive"

  conflict_detection:
    enabled: true
    on_conflict: "Flag for human resolution, don't add silently"
    check_on: [promotion_to_experimental, promotion_to_active]

# Control Runs
control_runs:
  frequency: "Every 5th run"
  configuration: "Execute with NO active lessons"
  purpose:
    - "Detect if lesson accumulation is helping or hurting"
    - "Establish baseline for comparison"
    - "Prevent self-reinforcing bias"
  comparison_metrics:
    - failure_rate
    - rubric_scores_per_phase
    - cost_per_run
    - time_per_run
  action_if_control_outperforms:
    - "Trigger full lesson audit"
    - "Consider resetting to curated subset"
